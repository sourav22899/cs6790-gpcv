Part A: Preprocessing : Input images Ia

1) Rectification : 
	Make epipolar Lines aligned with image rows


2) Pre Filtering : 
	Smooth to remove high frequency noise: 
			Choices :
				->Laplacian of Gaussian
				->Bilateral
				->For speed : Difference of boxes filter
	Return Ja

3) Correlation :
	Make disparity Map, by matching using SAD(Sum of absolute differences) or CENSUS
	disparity proportional to inverse range
	
	return Da

Interface : Ja,Da, frame number a, Jb,Db, frame number b

Part B : Actual Algo
1)Feature detection (Ja,Da;Jb,Db)->(Fa,Fb)
 Use Ja, Da and FAST/Harris to get world coordinates of feature points
	a) Discard features with unknown disparity
	b) m = odd number, construct an (mxm)-1 descriptor using the neighbourhood of each feature point(use a window of size mxm, eliminate the feature point)
	c) fa = [image location j, world coordinate w, descriptor s]
	d) Fa = {set of all such fa}
	e) repeat for getting Fb
	(Note, U already know Fa, because Fa now was the Fb of last iteration)

2)Score Matrix : (Fa,Fb)->S:
	S = matrix of dim (len(Fa)xlen(Fb))
	S[i,j] = SAD(Fa[s,i], Fb[s,j])  

3)Matching : (Fa,Fb,S)->M:
	Choices here : 	1)Hungarian Algo optimal(n^3)
		 	2)Greedy Suboptimal(n^2logn)
	HOwards:
		for each fa \in Fa
			choose fb' with min SAD
		for each fb \in Fb
			choose fa' with min SAD
		if(fa' == fa && fb' == fb)
			M.append(Match(fa,fb))
4)Maximum Inlier Set M -> Q
	Consistentcy Matrix W : len(M)xlen(M)
	(fa,fb) is consistent with (fa',fb') iff:
	|w_a -w_a'| + |w_b -w_b'| < delta  #Scope for improvement here
	
	FInd the maximum clique in graph with adjacency matrix W:
		1)choose node with max degree(max number of consistent matches) as initial set of 			  matches
		2)Find set of matches compatible with all the matches already considered
		3) Add these to the set of matches
		Repeat till 2 is empty
		Q = set of these matches
5) Q -> Estimating Motion
	We want a homogenous transform \Delta_{ab} that minimizes :
	
	eps = sum_{\forall fa,fb \in Q}  ((ja - P * \Delta * w_a)^2 + (jb - P * \Delta^{-1} * w_b)^2)
	where j = homogenous image coordinates
	      w = homogenous world coordinates
	      P = Camera Projection matrix
	Use LM here
	after finding the inital \delta_{ab}, discard any matches whose reprojection is above a threshold, and re run. This further removes outliers

6) Validation :
	1) min 3 points to generate a unique estimate, In real life, we ask for 3 points
	2) reprojection error needs to under a threshold(like 0.3 pixels)
	3) Colinearity of features 

		
		
		

	
	


